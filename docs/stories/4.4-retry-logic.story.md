# Story 4.4: Implement Retry Logic with Exponential Backoff

**Epic:** Marketplace Resilience System v2
**ID:** STORY-4.4
**Status:** Ready
**Complexity:** S (5 points)
**Time Estimate:** 2-3 days

---

## Story

Implement exponential backoff retry logic for failed job processing. Jobs that fail are automatically retried with increasing delays (1s → 5s → 30s).

**Dependencies:** Story 4.2 (BullMQ job queue)

---

## Acceptance Criteria

1. ✅ Retry delays: 1s, 5s, 30s (configurable)
2. ✅ Max retries: 3 (configurable)
3. ✅ Only retry on recoverable errors (network, timeout, rate limit)
4. ✅ Permanent errors (validation, auth) fail immediately
5. ✅ Dead-letter queue for failed jobs
6. ✅ Metrics tracked: retry count, delay duration, success rate
7. ✅ Logging shows retry attempt number and reason

---

## Scope

### IN (What we're doing)
- Retry strategy implementation
- Exponential backoff delay calculation
- Error classification (recoverable vs permanent)
- Dead-letter queue management
- Metrics tracking for retries
- Comprehensive logging of retry attempts
- Integration with BullMQ worker

### OUT (What we're NOT doing)
- Adaptive retry strategies (learning from patterns)
- Circuit breaker logic (covered in Story 4.3)
- Jitter in backoff delays (simple exponential)
- Job prioritization during retries

---

## Implementation Tasks

- [ ] Create `lib/resilience/retry-strategy.ts`
  - Calculate exponential backoff delay
  - Classify errors (recoverable vs permanent)
  - Generate retry schedule
  - Track retry metadata
- [ ] Update BullMQ worker to use retry strategy
  - Check error type before retry
  - Apply exponential backoff delay
  - Log retry attempts with context
- [ ] Update dead-letter queue handling
  - Archive failed jobs to database
  - Send notification when job enters DLQ
  - Store error details for analysis
- [ ] Update diagnostics endpoint
  - Show retry statistics per plan
  - Recommend manual intervention for DLQ items
  - Display most common error types
- [ ] Create unit tests for retry logic
- [ ] Create tests for error classification
- [ ] Update story File List

---

## Error Classification

**Recoverable Errors (should retry):**
- Network timeouts
- Connection refused
- Service unavailable (503, 429)
- Rate limit exceeded
- Temporary database errors
- Redis connection errors

**Permanent Errors (should NOT retry):**
- Validation errors (400)
- Authentication failures (401)
- Authorization failures (403)
- Not found errors (404)
- Malformed requests
- Missing required configuration

---

## Acceptance Test

```javascript
// Job fails on first attempt (recoverable error)
// Should retry after 1s delay
let callCount = 0;
agent.mockImplementation(() => {
  callCount++;
  if (callCount < 2) throw new Error('Network timeout');
  return { phases: [...] };
});

const job = await enqueuePhase1Job(planId);
// Initially pending
// After job worker picks up: ACTIVE (retry attempt 1)
// After error: scheduled with 1s delay
// After 1s: ACTIVE (retry attempt 2) → succeeds
// Final: COMPLETED with result
```

---

## Dev Notes

**Implementation considerations:**
- Retry delays: [1000ms, 5000ms, 30000ms] (configurable via .env)
- Max retries: 3 (configurable via .env)
- Error classification should be case-insensitive for error messages
- Permanent errors should fail immediately without retry
- DLQ archive should include full error trace and job payload
- Metrics should track: retry count, success rate, average delay
- Logging should use structured format with attempt number and error type

**Testing approach:**
- Mock agent to control success/failure scenarios
- Test each delay timing
- Test error classification logic
- Test DLQ archiving
- Test metrics collection
- Test behavior with different max retry counts

**Performance targets:**
- Retry calculation: < 5ms
- Error classification: < 2ms
- DLQ archiving: < 100ms
- Metrics update: < 10ms

---

## Testing

**Manual Testing:**
1. Trigger job that fails with recoverable error
2. Observe retry after 1s
3. Trigger job with permanent error
4. Verify no retries
5. Check DLQ for failed jobs
6. Verify diagnostics endpoint shows retry stats

**Automated Testing:**
- Exponential backoff delay calculation
- Error classification for all error types
- Retry count enforcement
- DLQ handling for permanent failures
- Metrics collection and accuracy
- Interaction with BullMQ worker

---

## File List

*After implementation, list all files created/modified:*

- [ ] lib/resilience/retry-strategy.ts
- [ ] lib/queue/phase1-worker.ts (modified)
- [ ] app/api/marketplace/diagnostics/route.ts (modified)
- [ ] __tests__/resilience/retry-strategy.test.ts
- [ ] __tests__/queue/phase1-worker.retry.test.ts

---

## Dev Agent Record

**Status:** Pending
**Assigned To:** @dev (Dex)
**Current Task:** Waiting for Story 4.2 completion

### Implementation Checkboxes
- [ ] Retry strategy class created
- [ ] Exponential backoff working
- [ ] Error classification implemented
- [ ] Worker integration complete
- [ ] Dead-letter queue handling working
- [ ] Metrics tracking functional
- [ ] Logging comprehensive
- [ ] Unit tests passing
- [ ] Integration tests passing
- [ ] Ready for QA review

### Debug Log
(Will be updated during implementation)

### Completion Notes
(Will be added when story completes)

---

## QA Results

(Will be populated by @qa Quinn)

---

## Change Log

- Created: 2026-02-23 (Marathon Phase 2)
- Validated: 2026-02-23 (by @po Pax) - 10/10 GO
- Status: Draft → Ready (APPROVED FOR IMPLEMENTATION)

---

## Story Metrics

| Metric | Value |
|--------|-------|
| Story Points | 5 |
| Time Estimate | 2-3 days |
| Complexity | Small |
| Priority | High (essential for reliability) |
| Risk | Low (isolated, well-defined scope) |
